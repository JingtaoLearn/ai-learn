# Open Claw

Self-hosted AI agent framework. Runs directly on the VM host (not in Docker).

## Architecture

Open Claw consists of two systemd user services that connect to Router-Maestro for LLM access:

1. **openclaw-proxy** (port 19999) — OpenAI-compatible reverse proxy that flattens multimodal content arrays into plain strings before forwarding to Router-Maestro (`maestro.us.jingtao.fun`).
2. **openclaw-gateway** (port 18789) — The main Open Claw gateway that serves agent requests. Routes model calls through the local proxy.

```
OpenClaw → Gateway (:18789) → Proxy (:19999) → Router-Maestro → GitHub Copilot → LLMs
```

### Router-Maestro Integration

[Router-Maestro](https://maestro.us.jingtao.fun) is a lightweight OpenAI-compatible proxy that provides access to multiple LLM providers, including **GitHub Copilot**. This setup enables OpenClaw to use:

- **GPT-5.2** and GPT-5.2-codex (via GitHub Copilot)
- **Claude models** (Opus 4.6, Sonnet 4.5, Haiku 4.5)
- Other GPT-5.x, GPT-4.x, and Gemini models

All models use the same `OPENCLAW_API_KEY` authentication token, eliminating the need for separate API keys per provider.

## Prerequisites

- Node.js (via nvm, fnm, or system package)
- npm with a global prefix configured (`~/.npm-global`)

## Installation

```bash
npm install -g openclaw
```

## Configuration

### Maximum Permissions Configuration

The `openclaw.json` file is configured with **maximum permissions** for full functionality. This includes:

**Tools Enabled:**
- `exec`, `process` - Command execution and process management
- `read`, `write`, `edit`, `apply_patch` - File system operations
- `browser` - Browser control (requires separate setup)
- `web`, `web_fetch`, `web_search` - Web access and search
- `memory` - Memory and embedding search
- `cron` - Scheduled task execution

**Security Features:**
- `sandbox.mode: "off"` - No sandboxing for maximum flexibility
- `elevated.enabled: true` - Allows privileged command execution
- `gateway.bind: "loopback"` - Restricts gateway to localhost only (recommended)
- `logging.redactSensitive: "tools"` - Redacts sensitive data in logs
- `discovery.mdns.mode: "minimal"` - Limits information disclosure

⚠️ **Security Warning:** This configuration grants extensive system access. Only use in trusted environments.

### Environment Variables

The following environment variables must be set (e.g., in `/etc/environment` via `vm/scripts/03-set-env.sh`):

| Variable | Description |
|---|---|
| `OPENCLAW_API_KEY` | API key for the upstream model provider |
| `OPENCLAW_GATEWAY_TOKEN` | Authentication token for gateway access (used in `openclaw.json`) |

### Symlinks

Configuration files in this repo are symlinked to their system locations so edits in either place stay in sync:

| Repo File | System Location |
|---|---|
| `openclaw.json` | `~/.openclaw/openclaw.json` |
| `openai-compat-proxy.js` | `~/.openclaw/openai-compat-proxy.js` |
| `systemd/openclaw-proxy.service` | `~/.config/systemd/user/openclaw-proxy.service` |

**Note:** `openclaw-gateway.service` is auto-generated by `openclaw gateway install` and is NOT symlinked. The `.example` file is stored here for reference only.

### Setup

Run the setup script to create symlinks and enable services:

```bash
./setup.sh
```

The script will:
- Validate that required environment variables are set
- Back up existing files before replacing with symlinks
- Create symlinks from system locations to repo files
- Reload systemd and enable/start both services

## Testing GPT-5.2 Integration

To verify that OpenClaw can access GPT-5.2 through Router-Maestro:

```bash
# Run comprehensive integration test
./test-gpt52.sh

# List available models
openclaw models list --all | grep "maestro/gpt-5"

# Test a specific model directly
curl -s -X POST http://127.0.0.1:19999/api/openai/v1/chat/completions \
  -H "Authorization: Bearer ${OPENCLAW_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-5.2","messages":[{"role":"user","content":"Hello"}],"max_tokens":50}' \
  | jq -r '.choices[0].message.content'
```

### Available GPT-5.2 Models

| Model | Description | Context | Provider |
|-------|-------------|---------|----------|
| `maestro/gpt-5.2` | GPT-5.2 (via GitHub Copilot) | 200k | github-copilot |
| `maestro/gpt-5.2-codex` | GPT-5.2 Codex (via GitHub Copilot) | 200k | github-copilot |
| `maestro/claude-opus-4.6` | Claude Opus 4.6 (default) | 200k | github-copilot |
| `maestro/claude-sonnet-4.5` | Claude Sonnet 4.5 (fallback) | 200k | github-copilot |
| `maestro/claude-haiku-4.5` | Claude Haiku 4.5 | 200k | github-copilot |

**Note:** All models are accessed through a single authentication key via Router-Maestro. No additional proxy layer is needed.

## Useful Commands

```bash
# Check service status
systemctl --user status openclaw-gateway openclaw-proxy

# View logs
journalctl --user -u openclaw-gateway -f
journalctl --user -u openclaw-proxy -f
tail -f /tmp/openclaw/openclaw-$(date +%Y-%m-%d).log

# Restart services
systemctl --user restart openclaw-proxy
systemctl --user restart openclaw-gateway

# Update openclaw
npm update -g openclaw
openclaw gateway install   # regenerates gateway service file

# Enable lingering (services persist after logout)
sudo loginctl enable-linger "$USER"

# Security validation
openclaw doctor --fix              # validate and fix configuration issues
openclaw security audit --deep     # deep security audit
chmod 700 ~/.openclaw              # secure directory permissions
chmod 600 ~/.openclaw/openclaw.json # secure config file

# Channel management
openclaw channels status
openclaw channels list
openclaw status --deep

# Test sending WhatsApp message
openclaw message send --channel whatsapp --target +1234567890 --message "Hello"
```

## WhatsApp Channel

### Setup

1. Enable the WhatsApp plugin:
```bash
openclaw plugins enable whatsapp
systemctl --user restart openclaw-gateway
```

2. Add WhatsApp channel:
```bash
openclaw channels add --channel whatsapp --name "WhatsApp"
```

3. Link your WhatsApp account (scan QR code with your phone):
```bash
openclaw channels login --channel whatsapp --verbose
```

### Troubleshooting

**Issue**: Not receiving messages

The WhatsApp channel uses a "pairing" DM policy by default. Messages from unknown senders will be blocked. To change this:

1. Check current config:
```bash
openclaw config get channels.whatsapp.accounts.default.dmPolicy
```

2. Allow all DMs (open mode - **not recommended for production**):
```bash
openclaw config set channels.whatsapp.accounts.default.dmPolicy open
systemctl --user restart openclaw-gateway
```

3. Or manage allowlist:
```bash
# List pairing requests
openclaw pairing list whatsapp

# Approve a sender
openclaw pairing approve whatsapp <code>
```

**Issue**: Connection keeps dropping

If you see "Connection Terminated" errors in logs, restart the gateway:
```bash
systemctl --user restart openclaw-gateway
# Wait a few seconds for WhatsApp to reconnect
sleep 5
openclaw status
```

## File Overview

```
open-claw/
├── README.md
├── setup.sh                               # Symlink + service setup
├── openclaw.json                          # Gateway config (symlinked)
├── openai-compat-proxy.js                 # Proxy script (symlinked)
└── systemd/
    ├── openclaw-gateway.service.example   # Reference only (auto-generated)
    └── openclaw-proxy.service             # Proxy unit file (symlinked)
```
